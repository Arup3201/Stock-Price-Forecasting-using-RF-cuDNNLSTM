{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2c1b9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For data processing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Save features as a pickle file\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df1551d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../datasets/datasets-list', 'rb') as file:\n",
    "    datasets = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe51a0e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets_combined = datasets # Create checkpoint\n",
    "len(datasets_combined)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b54836c",
   "metadata": {},
   "source": [
    "## Features Selection\n",
    "\n",
    "Let $T_{study}$ denote the total amount of days in a study period and $n_i$ represent the number of stocks $s$ in $S$ having complete historical data available at the end of each study period $i$. Moreover, we define the adjacent closing price and opening price of any stock $s \\in S$ at time $t$ by $cp^{(s)}_t$ and $op^{(s)}_t$.\n",
    "\n",
    "Given a prediction day $t:=\\tau$, we have the following inputs and prediction task.\n",
    "\n",
    "Input: We have the historical opening prices, $op^{(s)}_t, t \\in \\{ 0, 1, ..., \\tau -1, \\tau\\}$, (including the opening price of the prediction day $op^{(s)}_\\tau$) as well as the historical adjacent closing prices, $cp^{(s)}_t, t \\in \\{ 0, 1, ..., \\tau -1\\}$, (excluding the opening price of the prediction day $cp^{(s)}_\\tau$).\n",
    "\n",
    "Task: Out of all n stocks, predict k stocks with highest and k stocks with lowest intraday return $ir_{\\tau, 0} = \\dfrac{cp_\\tau}{op_\\tau} - 1$.\n",
    "\n",
    "**NOTE:** In the original paper they used all the stocks that could be scrapped from the web. Then they divided each stock into 26 datasets. Now, in this 26 datasets, some datasets may contain all 492 stocks that were originally scrapped and some datasets may contain only 251 stocks. That is why it is saying $s \\in S$ because each dataset will have different number of stocks and that will be a subset of all the originally scrapped stocks.\n",
    "\n",
    "But, in our case we are dealing with only those stocks which has all entries filled from 1990-01-02 to 2018-12-31. So, we have 251 stocks in all the datasets.\n",
    "\n",
    "\n",
    "\n",
    "For LaTex markdown, refer to this page: [here](https://ashki23.github.io/markdown-latex.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df8690eb",
   "metadata": {},
   "source": [
    "### Feature generation for Random Forest\n",
    "\n",
    "For any stock $s \\in S$ and any time $t \\in \\{ 241, 242, ..., T_{study} \\}$, the feature set we provide to the random forest comprises of 3 signal:\n",
    "\n",
    "1. Intraday return: $ir^{(s)}_{t, m} := \\dfrac{cp^{(s)}_{t-m}}{op^{(s)}_{t-m}} - 1$,\n",
    "\n",
    "\n",
    "2. Returns with respect to last closing price: $cr^{(s)}_{t, m} := \\dfrac{cp^{(s)}_{t-1}}{cp^{(s)}_{t-1-m}} - 1$,\n",
    "\n",
    "\n",
    "3. Returns with respect to opening price: $or^{(s)}_{t, m} := \\dfrac{op^{(s)}_{t}}{cp^{(s)}_{t-m}} - 1$,\n",
    "\n",
    "where $m \\in \\{ 1, 2, 3, ..., 20 \\} \\cup \\{ 40, 60, 80, ...., 240 \\}$, obtaining 93 features. By the choice of m we consider in the first month the corresponding returns of each trading day, whereas for the subsequent 11 months we only consider the corresponding multi-period returns of each month.\n",
    "\n",
    "![ir-cr-and-or-calculation.png](https://i.postimg.cc/T3sjRDQ1/ir-cr-and-or-calculation.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "505fd302",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function will generate new features for Random Forest\n",
    "def generate_features_rf(curr_dataset):\n",
    "\n",
    "    # Take the total amount of days in 1st study period\n",
    "    T_study = curr_dataset.shape[1]\n",
    "    print(\"current dataset has\", T_study, \" days.\")\n",
    "\n",
    "    # Create the t =[241, 243, ..., T_study]\n",
    "    t = np.arange(240, T_study)\n",
    "\n",
    "    # Define the m for calculation of t-m, m = [1, 2, 3, ..., 20]\n",
    "    M = np.arange(1, 21)\n",
    "\n",
    "    # m = [1, 2, 3, ..., 20] U [40, 60, 80, ..., 240]\n",
    "    M = np.concatenate((M, np.arange(40, 241, 20)))\n",
    "\n",
    "    # Define number of stocks as it will be used to create arrays with proper shapes\n",
    "    n_stocks = 251\n",
    "\n",
    "    # Create a container to store ir, cr and or for the current dataset\n",
    "    container = np.ones(shape=(n_stocks, T_study, M.shape[0]*3))\n",
    "\n",
    "    # Put NaN values to the first 240 rows as it will be used for feature creation\n",
    "    container[:, :t[0], :] = np.nan \n",
    "\n",
    "\n",
    "    # To calculate ir, we need cp_(t-m) and op_(t-m)\n",
    "    cp_t_m = np.zeros((n_stocks, t.shape[0], M.shape[0]))\n",
    "    op_t_m = np.zeros((n_stocks, t.shape[0], M.shape[0]))\n",
    "\n",
    "    # To calculate cr, we need cp_(t-1-m) and cp_(t-1-m). Remember we are indexing from 0, not 1!\n",
    "    cp_t_1_m = np.zeros((n_stocks, t.shape[0], M.shape[0]))\n",
    "    cp_t_1 = curr_dataset[:, t-2, 0]\n",
    "\n",
    "    # To calculate or, we need op_t and cp_t_m. Remember we are indexing from 0, not 1!\n",
    "    op_t = curr_dataset[:, t-1, 1]\n",
    "\n",
    "\n",
    "    # Calculate cp_(t-m), op_(t-m) and cp_(t-1-m) for each m and store them at proper axis=2 index i\n",
    "    # of their respective container\n",
    "    for i, m in enumerate(M):\n",
    "        cp_t_m[:, :, i] = curr_dataset[:, t-m, 0]\n",
    "        op_t_m[:, :, i] = curr_dataset[:, t-m, 1]\n",
    "        cp_t_1_m[:, :, i] = curr_dataset[:, t-1-m, 0]\n",
    "\n",
    "\n",
    "    # Calculate ir_(t-m)\n",
    "    ir_t_m = np.divide(cp_t_m, op_t_m, out=np.zeros_like(cp_t_m), where=op_t_m!=0) - 1\n",
    "\n",
    "\n",
    "    # Before calculating cr_(t-m), reshape the cp_(t-1-m) as it should have the same last part of shape as cp_(t-1), the divident\n",
    "    # means if cp_(t-1) is (251, 774) then cp_(t-1-m) should be (_, 251, 774) notice the last of shape is same\n",
    "    reshaped_cp_t_1_m = cp_t_1_m.reshape(M.shape[0], n_stocks, -1)\n",
    "\n",
    "    # Calculating cr_(t-m)\n",
    "    cr_t_m = np.divide(cp_t_1, reshaped_cp_t_1_m, where=reshaped_cp_t_1_m!=0).reshape(n_stocks, -1, M.shape[0]) - 1\n",
    "\n",
    "\n",
    "    # Before calculating or_(t-m), reshape the cp_(t-m) as it should have the same last part of shape as op_t, the divident\n",
    "    # means if op_t is (251, 774) then cp_(t-m) should be (_, 251, 774) notice the last of shape is same\n",
    "    reshaped_cp_t_m = cp_t_m.reshape(M.shape[0], n_stocks, -1)\n",
    "\n",
    "    # Calculating or_(t-m)\n",
    "    or_t_m = np.divide(op_t, reshaped_cp_t_m, where=reshaped_cp_t_m!=0).reshape(n_stocks, -1, M.shape[0]) - 1\n",
    "\n",
    "\n",
    "    # Put the ir, cr and or inside the container\n",
    "    container[:, t, :] = np.dstack((ir_t_m, cr_t_m, or_t_m))\n",
    "\n",
    "    return container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6aed74fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current dataset has 1013  days.\n",
      "current dataset has 1012  days.\n",
      "current dataset has 1011  days.\n",
      "current dataset has 1011  days.\n",
      "current dataset has 1011  days.\n",
      "current dataset has 1011  days.\n",
      "current dataset has 1011  days.\n",
      "current dataset has 1009  days.\n",
      "current dataset has 1004  days.\n",
      "current dataset has 1004  days.\n",
      "current dataset has 1004  days.\n",
      "current dataset has 1004  days.\n",
      "current dataset has 1008  days.\n",
      "current dataset has 1007  days.\n",
      "current dataset has 1006  days.\n",
      "current dataset has 1007  days.\n",
      "current dataset has 1007  days.\n",
      "current dataset has 1008  days.\n",
      "current dataset has 1009  days.\n",
      "current dataset has 1006  days.\n",
      "current dataset has 1006  days.\n",
      "current dataset has 1006  days.\n",
      "current dataset has 1006  days.\n",
      "current dataset has 1008  days.\n",
      "current dataset has 1007  days.\n",
      "current dataset has 1005  days.\n"
     ]
    }
   ],
   "source": [
    "# It will contain all the newly processed datasets each with a shape (251, stock days in 4 years, 93)\n",
    "containers = []\n",
    "\n",
    "# Run the generate_feature_rf function for each dataset inside main_datasets\n",
    "for dataset in datasets_combined:\n",
    "    containers.append(generate_features_rf(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d600c6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(containers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f8c570f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../features/rf-features-part1', 'wb') as file:\n",
    "    pickle.dump(containers[:13], file)\n",
    "\n",
    "with open('../features/rf-features-part2', 'wb') as file:\n",
    "    pickle.dump(containers[13:], file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stock-kernel",
   "language": "python",
   "name": "stock-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
