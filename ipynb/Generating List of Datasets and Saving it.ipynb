{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02af4f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For data processing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Save the list datasets inside datasets pickle file\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b93b35",
   "metadata": {},
   "source": [
    "### Preparing the original dataset for further processing\n",
    "\n",
    "*Segregate the stocks within different numpy arrays according to the ticker name.*\n",
    "![Stack-stock-data-on-top-of-each-other.png](https://i.postimg.cc/HnDyJp9s/Stack-stock-data-on-top-of-each-other.png)\n",
    "\n",
    "WARNING❗ \n",
    "- Different stocks will give different no. of rows, as all stocks were not always available in that time span.\n",
    "- Here we are not able to properly get all days values.\n",
    "\n",
    "To prevent the error, we are removing those stocks will are having empty values for those dates.\n",
    "\n",
    "E.g. Stock A might start from 1991-01-01 and Stock B from 1990-12-31 then both of them are not in same shape. So we can remove stock B. Making sure all stocks are having same no of rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3fbfdf7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the data from your drive\n",
    "df = pd.read_csv('../datasets/stock-prices-S&P-constituents/stocks-data.csv')\n",
    "df = df.set_index('Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc1225ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ticker of each stock\n",
    "symbols = df['Symbol'].unique()\n",
    "\n",
    "n_stocks = len(symbols) # number of stocks\n",
    "\n",
    "stocks = [] # Store the stocks data inside stocks list\n",
    "filtered_symbols = [] # This are the symbols for those stocks which have 7307 rows only\n",
    "\n",
    "# segregate the stocks within different numpy arrays according to the ticker name\n",
    "for i in range(n_stocks):\n",
    "    total_captured_days = np.delete(df[df['Symbol'] == symbols[i]].reset_index().to_numpy(), 1, axis=1).shape[0]\n",
    "    # Just take those stocks which was available from 1990-01-01 to 2018-12-31\n",
    "    if total_captured_days == n_rows:\n",
    "        stocks.append(np.delete(df[df['Symbol'] == symbols[i]].reset_index().to_numpy(), 1, axis=1))\n",
    "        filtered_symbols.append(symbols[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0a6c074",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a check point\n",
    "final_stocks = stocks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0063774b",
   "metadata": {},
   "source": [
    "*Total number of stocks now are only 251. But we made sure these 251 stocks have same no of rows.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e93da49b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(251, 251, list)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(final_stocks), len(filtered_symbols), type(final_stocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd9f4a89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray, (251, 7307, 7))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the list into array for smooth manipulation of data later\n",
    "final_stocks = np.array(final_stocks)\n",
    "type(final_stocks), final_stocks.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76440423",
   "metadata": {},
   "source": [
    "We just need opening price and adjacent closing price, so we can remove other features like Volume, Min, Max etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9fae6033",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Close</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1990-01-02</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>0.264482</td>\n",
       "      <td>0.332589</td>\n",
       "      <td>0.334821</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.314732</td>\n",
       "      <td>183198400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990-01-03</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>0.266257</td>\n",
       "      <td>0.334821</td>\n",
       "      <td>0.339286</td>\n",
       "      <td>0.334821</td>\n",
       "      <td>0.339286</td>\n",
       "      <td>207995200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990-01-04</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>0.267145</td>\n",
       "      <td>0.335938</td>\n",
       "      <td>0.345982</td>\n",
       "      <td>0.332589</td>\n",
       "      <td>0.341518</td>\n",
       "      <td>221513600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990-01-05</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>0.268033</td>\n",
       "      <td>0.337054</td>\n",
       "      <td>0.341518</td>\n",
       "      <td>0.330357</td>\n",
       "      <td>0.337054</td>\n",
       "      <td>123312000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990-01-08</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>0.269808</td>\n",
       "      <td>0.339286</td>\n",
       "      <td>0.339286</td>\n",
       "      <td>0.330357</td>\n",
       "      <td>0.334821</td>\n",
       "      <td>101572800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-24</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>35.375175</td>\n",
       "      <td>36.707500</td>\n",
       "      <td>37.887501</td>\n",
       "      <td>36.647499</td>\n",
       "      <td>37.037498</td>\n",
       "      <td>148676800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-26</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>37.866348</td>\n",
       "      <td>39.292500</td>\n",
       "      <td>39.307499</td>\n",
       "      <td>36.680000</td>\n",
       "      <td>37.075001</td>\n",
       "      <td>234330000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-27</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>37.620605</td>\n",
       "      <td>39.037498</td>\n",
       "      <td>39.192501</td>\n",
       "      <td>37.517502</td>\n",
       "      <td>38.959999</td>\n",
       "      <td>212468400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-28</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>37.639881</td>\n",
       "      <td>39.057499</td>\n",
       "      <td>39.630001</td>\n",
       "      <td>38.637501</td>\n",
       "      <td>39.375000</td>\n",
       "      <td>169165600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-31</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>38.003689</td>\n",
       "      <td>39.435001</td>\n",
       "      <td>39.840000</td>\n",
       "      <td>39.119999</td>\n",
       "      <td>39.632500</td>\n",
       "      <td>140014000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7307 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Symbol  Adj Close      Close       High        Low       Open   \n",
       "Date                                                                       \n",
       "1990-01-02   AAPL   0.264482   0.332589   0.334821   0.312500   0.314732  \\\n",
       "1990-01-03   AAPL   0.266257   0.334821   0.339286   0.334821   0.339286   \n",
       "1990-01-04   AAPL   0.267145   0.335938   0.345982   0.332589   0.341518   \n",
       "1990-01-05   AAPL   0.268033   0.337054   0.341518   0.330357   0.337054   \n",
       "1990-01-08   AAPL   0.269808   0.339286   0.339286   0.330357   0.334821   \n",
       "...           ...        ...        ...        ...        ...        ...   \n",
       "2018-12-24   AAPL  35.375175  36.707500  37.887501  36.647499  37.037498   \n",
       "2018-12-26   AAPL  37.866348  39.292500  39.307499  36.680000  37.075001   \n",
       "2018-12-27   AAPL  37.620605  39.037498  39.192501  37.517502  38.959999   \n",
       "2018-12-28   AAPL  37.639881  39.057499  39.630001  38.637501  39.375000   \n",
       "2018-12-31   AAPL  38.003689  39.435001  39.840000  39.119999  39.632500   \n",
       "\n",
       "                 Volume  \n",
       "Date                     \n",
       "1990-01-02  183198400.0  \n",
       "1990-01-03  207995200.0  \n",
       "1990-01-04  221513600.0  \n",
       "1990-01-05  123312000.0  \n",
       "1990-01-08  101572800.0  \n",
       "...                 ...  \n",
       "2018-12-24  148676800.0  \n",
       "2018-12-26  234330000.0  \n",
       "2018-12-27  212468400.0  \n",
       "2018-12-28  169165600.0  \n",
       "2018-12-31  140014000.0  \n",
       "\n",
       "[7307 rows x 7 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['Symbol']=='AAPL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "06de6de4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['1990-01-02', 0.2644821405410766, 0.3325890004634857,\n",
       "       0.3348209857940674, 0.3125, 0.3147319853305816, 183198400.0],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_stocks[0, 0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7c8d902c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.3325890004634857, 0.3348209857940674], dtype=object), 183198400.0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_stocks[0, 0, 2:4], final_stocks[0, 0, 6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "328fa475",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(251, 7307, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_stocks = np.delete(final_stocks, np.s_[2:5], axis=2) # Delete Close, High, Low columns \n",
    "final_stocks = np.delete(final_stocks, 3, axis=2) # Delete Volume column, NOTE after first deletion index is changed\n",
    "final_stocks.shape # Now it only contains Date, Adj Close and Open"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f83b2d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_stocks[:, :, 0] = np.array([pd.to_datetime(stock_i).date for stock_i in final_stocks[:, :, 0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8aa0c8fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.date(1990, 1, 2)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_stocks[0, 0, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b32e8f6e",
   "metadata": {},
   "source": [
    "### Datasets creation with non-overlapping testing period from original dataset\n",
    "\n",
    "We divide the dataset contsisting of 29 years starting from January 1990 till December 2018, using a 4-year window, 1-year stride, where each study period is divided into a training part(of 756 days almost = 3 years) and trading part(of 252 days almost = 1 year).\n",
    "\n",
    "So, we obtain 26 study periods with non-overlapping trading part.\n",
    "\n",
    "![Dataset-creation-with-non-overlapping-testing-period.png](https://i.postimg.cc/7YWw5YwL/Dataset-creation-with-non-overlapping-testing-period.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e8f3901",
   "metadata": {},
   "source": [
    "**METHOD TO CREATE THE NON-OVERLAPPING TESTING PERIODS**\n",
    "\n",
    "1. Store the dates inside temp variable.\n",
    "\n",
    "  ![dates-layed-out-in-stock-price-prediction.png](https://i.postimg.cc/65MCHfGk/dates-layed-out-in-stock-price-prediction.png)\n",
    "\n",
    "2. Define 2 variables. `year_start` that will point to the starting day of each dataset and `start_index` which will tell what is the exact index number of that starting day.\n",
    "  ![year-start-start-index-variables.png](https://i.postimg.cc/MGvP8krx/year-start-start-index-variables.png)\n",
    "\n",
    "3. `year_start` will go till `2015`. As 2015-2018 is the last last study period.\n",
    "\n",
    "4. Another variable called `year_end` will point to the end of the year. To be precise it is not exactly the end of the last year but one day after the last day. I.e. if the `year_start = '1990-01-02'` then `year_end = '1994-01-02'`.\n",
    "\n",
    "  Why this will make any sense?\n",
    "\n",
    "  The reason is, we will try to find the exact index value of the first day and last day inside each dataset.\n",
    "  Then, we will use condition indexing using those indexes. Now, we made the `year_end` like that because it will take less efforts to change the year value of `year_start` by `window_size` to get `year_end`. Then, in the condition we not include this `year_end`.\n",
    "  \n",
    "  ![year-end.png](https://i.postimg.cc/XY9CjPWR/year-end.png)\n",
    "\n",
    "5. Index the `temp` that contained the whole 29 years time from `year_start`(including) to `year_end`(excluding). Condition will be `temp[(temp>=year_start) & (temp<year_end)]`. This is the `timeline` of the current dataset(not yet created!).\n",
    "  ![timeline-creation.png](https://i.postimg.cc/JzrDkWfL/timeline-creation.png)\n",
    "\n",
    "6. Calculate the `end_index` using the length of the current dataset's timeline and `start_index`. \n",
    "  \n",
    "  `end_index = start_index + len(timeline)`\n",
    "  ![progress-of-end-index.png](https://i.postimg.cc/T2rzsZHB/progress-of-end-index.png)\n",
    "\n",
    "7. Slice the data from `start_index` to `end_index`(excluding). As the date is now useless for our further steps. So make sure to delete the date part by slicing from `index=1` till end as date's index = 0.\n",
    "\n",
    "  `data[:, start_index:end_index, 1:]`\n",
    "  \n",
    "  Then append it to `datasets` list.\n",
    "\n",
    "8. Finally update the `year_start` by moving the previous `year_start` `stride=1` year. If the `year_start` is `1990-01-02` then next time it will be `1991-01-02`.\n",
    "![progress-year-start.png](https://i.postimg.cc/HkwvsY30/progress-year-start.png)\n",
    "\n",
    "9. Now, as we have the new `year_start`, we will use it to find the `before_start_timeline` that has passed from `1990-01-02`. This timeline will store the days from `1990-01-02` to the current `year_start` date.\n",
    "\n",
    "  It will help us find the new `start_index`. We need to just find the length of this `before_start_timeline` or in other words how many days have passed from `1990-01-02` till the current `year_start`.\n",
    "\n",
    "![progress-of-start-index.png](https://i.postimg.cc/dtcKLdWy/progress-of-start-index.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5b0172c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_generator(data, window_size=4, stride=1):\n",
    "    '''\n",
    "    data: stocks data containing date from 1990 to 2018 -> dims = (_, _, _)\n",
    "    window_size: no of years contained inside any dataset -> int\n",
    "    stride: by how much amount the window should slide -> int\n",
    "\n",
    "    returns list of datasets each having 'window_size'ed years of stock data -> list\n",
    "    '''\n",
    "\n",
    "    # datasets -> [D1, D2, D3, ..., D26], Di will be a (251, 4 year time length, 2)\n",
    "    datasets = []\n",
    "\n",
    "    # Step 1\n",
    "    temp = data[0, :, 0]\n",
    "\n",
    "    # Step 2\n",
    "    year_start = data[0, 0, 0]\n",
    "    start_index = 0\n",
    "\n",
    "    # Step 3\n",
    "    while year_start.year<=2015:\n",
    "\n",
    "        # Step 4\n",
    "        year_end = year_start.replace(year=year_start.year+window_size)\n",
    "\n",
    "        # Step 5\n",
    "        timeline = temp[(temp>=year_start) & (temp<year_end)]\n",
    "\n",
    "        # Step 6\n",
    "        end_index = start_index + timeline.shape[0]\n",
    "\n",
    "        # Step 7\n",
    "        datasets.append(data[:, start_index:end_index, 1:])\n",
    "\n",
    "        # Step 8\n",
    "        year_start = year_start.replace(year=year_start.year+stride)\n",
    "\n",
    "        # Step 9\n",
    "        before_start_timeline = temp[temp<=year_start]\n",
    "        start_index = len(before_start_timeline)\n",
    "\n",
    "    return datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3295c940",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = dataset_generator(final_stocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dfcb2347",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4c63add0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(251, 1013, 2)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8f678d18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.2644821405410766, 0.3147319853305816], dtype=object)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets[0][0, 0, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da15cc4f",
   "metadata": {},
   "source": [
    "Order of values for the above result : *Adj Close, Open*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d56d7080",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../datasets/datasets-list', 'wb') as file:\n",
    "    pickle.dump(datasets, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f3fc1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../datasets/symbols', 'wb') as file:\n",
    "    pickle.dump(filtered_symbols, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stock-kernel",
   "language": "python",
   "name": "stock-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
