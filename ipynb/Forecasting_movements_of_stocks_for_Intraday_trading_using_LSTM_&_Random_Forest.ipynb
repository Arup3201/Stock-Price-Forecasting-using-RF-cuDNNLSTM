{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DBZJPg65wYKT",
    "outputId": "112c68e8-df8c-4ae2-807b-d17d8508aff2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(251, 1013, 93)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DEMO CODE 👇\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "25AbDpT-SQCk"
   },
   "source": [
    "#  Forecasting directional movements of stock prices for intraday trading using Random Forest & CuDNNLSTM\n",
    "\n",
    "-----------------------------------------------------------\n",
    "*What Is Intraday Return?*\n",
    "\n",
    "The intraday return is one of the two components of the total daily return generated by a stock. Intraday return measures the return generated by a stock during regular trading hours, based on its price change from the opening of a trading day to its close. Intraday return and overnight return together constitute the total daily return from a stock, which is based on the price change of a stock from the close of one trading day to the close of the next trading day. It is also called daytime return.\n",
    "\n",
    "Intraday return is of particular importance for day traders, who use daytime gyrations in stocks and markets to make trading profits, and rarely leave positions open overnight. Day trading strategies are not as commonplace for regular investors as they were before the 2008-2009 recession.\n",
    "\n",
    "---------------------------------------------------------\n",
    "*How to Calculate Daily Returns?*\n",
    "\n",
    "To calculate a daily return, you subtract the starting price from the closing price. Once you have that, you simply multiply by the number of shares you own.\n",
    "\n",
    "To illustrate, let's say you own `100` shares of XYZ stock. The day opens at `$20` and closes at `$25`. This is a `$5` positive difference. Multiply the `$5` difference by the `100` shares you own, for a daily return of `$500`.\n",
    "\n",
    "Some investors will prefer to work in percentages rather than dollar amounts. This is only slightly more complicated. You perform the same first step and arrive at a `$5` gain per share for the day. You then divide by the opening price of `$25`, leaving you with `0.2`. Multiply by `100` to arrive at your daily return of `20%`.\n",
    "\n",
    "-----------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A7HVMz79RJ8v"
   },
   "source": [
    "This project is done by following the methods and techniques of the paper `Forecasting directional movements of stock prices for intraday trading using LSTM and random forests`. Link to the paper: [Click Here](https://arxiv.org/pdf/2004.10178.pdf).\n",
    "\n",
    "This introduces multi-feature setting consisting not only of the returns with respect to the closing prices, but also with respect to the opening prices and intraday returns to predict each stock, at the beginning of each day, the probablity to outperform the market in terms of intraday returns.\n",
    "\n",
    "As dataset we use all stocks of the S&P 500 from the period of January 1990 until December 2018.\n",
    "\n",
    "We employ both Random Forests on the one hand and LSTM on the other hand as training methodology."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UyxAjLk6cXMc"
   },
   "source": [
    "### Technology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VOFu4PhEdkK3"
   },
   "source": [
    "- Python: 3.9.16\n",
    "- Scikit-Learn: 1.2.2\n",
    "- Tensorflow: 2.12.0\n",
    "- System RAM: 12.7 GB\n",
    "- GPU RAM: 15.0 GB\n",
    "- Disk: 78.2 GB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7JsDmuufYS1K"
   },
   "source": [
    "## Library Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "jErs_PBbSjM9"
   },
   "outputs": [],
   "source": [
    "# Download the historical price of stocks using yfinance\n",
    "## Scrape the wikipedia page to get ticker names using BeautifulSoup and requests\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "## Download the stock prices using yfinance\n",
    "import yfinance as yf\n",
    "\n",
    "# For data processing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# For Random Forest\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# LSTM and other layers\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gzrx5Q7DYixY"
   },
   "source": [
    "## Download stock data\n",
    "\n",
    "**RUN THE CELLS BELOW ONCE IF YOU ARE USING THIS IPYNB FILE FOR THE FIRST TIME.\n",
    "THE CELLS BELOW WILL DOWNLOAD THE DATA IN THE DRIVE FOLDER `datasets/stock-prices-S&P-constituents` as `stocks-data.csv`. So, make sure to create this folder `datasets/stock-prices-S&P-constituents` if not present inside your drive.**\n",
    "\n",
    "\n",
    "**BUT IF YOU ALREADY HAVE RUN THE BELOW CELLS ONCE THEN NO NEED TO RUN THEM AGAIN!! OTHERWISE, IT WILL AGAIN DOWNLOAD THE DATA WHICH WILL TAKE TIME TO COMPLETE!!**\n",
    "\n",
    "----------------------------------------------------------\n",
    "\n",
    "**Download the S&P 500 stocks price data**\n",
    "\n",
    "The S&P 500 stock market index is maintained by S&P Dow Jones Indices. It comprises 503 common stocks which are issued by 500 large-cap companies traded on American stock exchanges (including the 30 companies that compose the Dow Jones Industrial Average). The index includes about 80 percent of the American equity market by capitalization. It is weighted by free-float market capitalization, so more valuable companies account for relatively more weight in the index. The index constituents and the constituent weights are updated regularly using rules published by S&P Dow Jones Indices. Although called the S&P 500, the index contains 503 stocks because it includes two share classes of stock from 3 of its component companies.\n",
    "\n",
    "-----------------------------------------------------------\n",
    "- Start Date: 1989-12-31\n",
    "- End Sate: 2019-01-01\n",
    "\n",
    "To clear any confusion we are actually taking stock price data from 1990-01-01 to 2018-12-31. But, at the time of downloading if we provide the exact dates then the stock price at those days will be excluded. So, we are taking dates 1 step before and after them respectively.\n",
    "\n",
    "Web scraping code explanation: [Click Here](https://wire.insiderfinance.io/how-to-get-all-stocks-from-the-s-p500-in-python-fbe5f9cb2b61)\n",
    "\n",
    "Scraped website link: [wikipedia link](https://en.wikipedia.org/wiki/List_of_S%26P_500_companies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T2UxGJaSnlyT",
    "outputId": "ff885519-527a-4a46-ae54-24d37754d10d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('MMM\\n', 'AOS\\n', 'ZTS\\n', 503)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = requests.get(\"https://en.wikipedia.org/wiki/List_of_S%26P_500_companies\")\n",
    "soup = BeautifulSoup(res.text, 'lxml')\n",
    "table = soup.findAll('table', {'class': 'wikitable sortable'})\n",
    "\n",
    "tickers = []\n",
    "\n",
    "for row in table[0].findAll('tr')[1:]:\n",
    "  ticker = row.findAll('td')[0].text\n",
    "  tickers.append(ticker)\n",
    "\n",
    "tickers[0], tickers[1], tickers[-1], len(tickers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IIRTLNjesvKl",
    "outputId": "8688826e-b77d-415c-cb91-822a55110661"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('MMM', 'AOS', 'ZTS')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tickers = [ticker.replace('\\n', '') for ticker in tickers]\n",
    "tickers[0], tickers[1], tickers[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8vM5bSOxZvhm",
    "outputId": "0634b7b6-190d-40ab-b07c-7837ebc37b50"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  503 of 503 completed\n",
      "\n",
      "11 Failed downloads:\n",
      "- FOX: Data doesn't exist for startDate = 631083600, endDate = 1546318800\n",
      "- OGN: Data doesn't exist for startDate = 631083600, endDate = 1546318800\n",
      "- CARR: Data doesn't exist for startDate = 631083600, endDate = 1546318800\n",
      "- GEHC: Data doesn't exist for startDate = 631083600, endDate = 1546318800\n",
      "- DOW: Data doesn't exist for startDate = 631083600, endDate = 1546318800\n",
      "- CTVA: Data doesn't exist for startDate = 631083600, endDate = 1546318800\n",
      "- CEG: Data doesn't exist for startDate = 631083600, endDate = 1546318800\n",
      "- BF.B: No data found for this date range, symbol may be delisted\n",
      "- FOXA: Data doesn't exist for startDate = 631083600, endDate = 1546318800\n",
      "- OTIS: Data doesn't exist for startDate = 631083600, endDate = 1546318800\n",
      "- BRK.B: No timezone found, symbol may be delisted\n"
     ]
    }
   ],
   "source": [
    "start_date = \"1989-12-31\"\n",
    "end_date = \"2019-01-01\"\n",
    "\n",
    "# Download the data\n",
    "data = yf.download(tickers, start_date, end_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mZBWzsPNtpR-"
   },
   "source": [
    "We got the stock price data for 492 stocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 724
    },
    "id": "waPTTdRtt4PF",
    "outputId": "35004b64-93c1-486d-ff76-92f8d2814735"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"10\" halign=\"left\">Adj Close</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"10\" halign=\"left\">Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>AAL</th>\n",
       "      <th>AAP</th>\n",
       "      <th>AAPL</th>\n",
       "      <th>ABBV</th>\n",
       "      <th>ABC</th>\n",
       "      <th>ABT</th>\n",
       "      <th>ACGL</th>\n",
       "      <th>ACN</th>\n",
       "      <th>ADBE</th>\n",
       "      <th>...</th>\n",
       "      <th>WYNN</th>\n",
       "      <th>XEL</th>\n",
       "      <th>XOM</th>\n",
       "      <th>XRAY</th>\n",
       "      <th>XYL</th>\n",
       "      <th>YUM</th>\n",
       "      <th>ZBH</th>\n",
       "      <th>ZBRA</th>\n",
       "      <th>ZION</th>\n",
       "      <th>ZTS</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1990-01-02</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.264482</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.846023</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.188340</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>247200</td>\n",
       "      <td>5326000</td>\n",
       "      <td>18000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53600</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990-01-03</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.266257</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.852688</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.247023</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>126800</td>\n",
       "      <td>4980400</td>\n",
       "      <td>79200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>111200</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990-01-04</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.267145</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.849356</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.305707</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>204200</td>\n",
       "      <td>6013200</td>\n",
       "      <td>25200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1600</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990-01-05</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.268033</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.829362</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.335048</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>144800</td>\n",
       "      <td>3854800</td>\n",
       "      <td>92400</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990-01-08</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.269808</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.838740</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.352692</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>189000</td>\n",
       "      <td>4302000</td>\n",
       "      <td>98400</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1600</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-24</th>\n",
       "      <td>60.658112</td>\n",
       "      <td>29.247074</td>\n",
       "      <td>138.501755</td>\n",
       "      <td>35.375175</td>\n",
       "      <td>68.045479</td>\n",
       "      <td>66.140625</td>\n",
       "      <td>60.909615</td>\n",
       "      <td>24.799999</td>\n",
       "      <td>125.596733</td>\n",
       "      <td>205.160004</td>\n",
       "      <td>...</td>\n",
       "      <td>2225000.0</td>\n",
       "      <td>2810600</td>\n",
       "      <td>14262800</td>\n",
       "      <td>1204200</td>\n",
       "      <td>542800.0</td>\n",
       "      <td>1806000.0</td>\n",
       "      <td>959548.0</td>\n",
       "      <td>363000.0</td>\n",
       "      <td>1504800</td>\n",
       "      <td>1551400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-26</th>\n",
       "      <td>63.435986</td>\n",
       "      <td>31.776182</td>\n",
       "      <td>144.184311</td>\n",
       "      <td>37.866348</td>\n",
       "      <td>71.991096</td>\n",
       "      <td>68.271774</td>\n",
       "      <td>64.681633</td>\n",
       "      <td>25.920000</td>\n",
       "      <td>130.614212</td>\n",
       "      <td>222.949997</td>\n",
       "      <td>...</td>\n",
       "      <td>3506200.0</td>\n",
       "      <td>5029800</td>\n",
       "      <td>24887700</td>\n",
       "      <td>2309900</td>\n",
       "      <td>806200.0</td>\n",
       "      <td>2030200.0</td>\n",
       "      <td>1667776.0</td>\n",
       "      <td>327200.0</td>\n",
       "      <td>2969800</td>\n",
       "      <td>1869700.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-27</th>\n",
       "      <td>64.345802</td>\n",
       "      <td>31.530161</td>\n",
       "      <td>143.868118</td>\n",
       "      <td>37.620605</td>\n",
       "      <td>72.694504</td>\n",
       "      <td>68.729782</td>\n",
       "      <td>65.619972</td>\n",
       "      <td>26.540001</td>\n",
       "      <td>131.929642</td>\n",
       "      <td>225.139999</td>\n",
       "      <td>...</td>\n",
       "      <td>4229900.0</td>\n",
       "      <td>4759500</td>\n",
       "      <td>22077000</td>\n",
       "      <td>2042600</td>\n",
       "      <td>790800.0</td>\n",
       "      <td>2081600.0</td>\n",
       "      <td>1626267.0</td>\n",
       "      <td>504500.0</td>\n",
       "      <td>2534200</td>\n",
       "      <td>2244700.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-28</th>\n",
       "      <td>64.000351</td>\n",
       "      <td>31.323500</td>\n",
       "      <td>144.584229</td>\n",
       "      <td>37.639885</td>\n",
       "      <td>73.672821</td>\n",
       "      <td>69.131706</td>\n",
       "      <td>66.047363</td>\n",
       "      <td>26.389999</td>\n",
       "      <td>131.375290</td>\n",
       "      <td>223.130005</td>\n",
       "      <td>...</td>\n",
       "      <td>2316100.0</td>\n",
       "      <td>5728300</td>\n",
       "      <td>19710600</td>\n",
       "      <td>1763500</td>\n",
       "      <td>782800.0</td>\n",
       "      <td>1699500.0</td>\n",
       "      <td>1915800.0</td>\n",
       "      <td>344800.0</td>\n",
       "      <td>2558600</td>\n",
       "      <td>1797300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-31</th>\n",
       "      <td>65.455811</td>\n",
       "      <td>31.599043</td>\n",
       "      <td>146.444290</td>\n",
       "      <td>38.003681</td>\n",
       "      <td>74.537941</td>\n",
       "      <td>69.542992</td>\n",
       "      <td>67.199402</td>\n",
       "      <td>26.719999</td>\n",
       "      <td>132.493423</td>\n",
       "      <td>226.240005</td>\n",
       "      <td>...</td>\n",
       "      <td>2609800.0</td>\n",
       "      <td>4485400</td>\n",
       "      <td>15807000</td>\n",
       "      <td>1664300</td>\n",
       "      <td>663800.0</td>\n",
       "      <td>1657000.0</td>\n",
       "      <td>1431391.0</td>\n",
       "      <td>409100.0</td>\n",
       "      <td>2575600</td>\n",
       "      <td>1485200.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7307 rows × 3018 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Adj Close                                                           \n",
       "                    A        AAL         AAP       AAPL       ABBV        ABC   \n",
       "Date                                                                            \n",
       "1990-01-02        NaN        NaN         NaN   0.264482        NaN        NaN  \\\n",
       "1990-01-03        NaN        NaN         NaN   0.266257        NaN        NaN   \n",
       "1990-01-04        NaN        NaN         NaN   0.267145        NaN        NaN   \n",
       "1990-01-05        NaN        NaN         NaN   0.268033        NaN        NaN   \n",
       "1990-01-08        NaN        NaN         NaN   0.269808        NaN        NaN   \n",
       "...               ...        ...         ...        ...        ...        ...   \n",
       "2018-12-24  60.658112  29.247074  138.501755  35.375175  68.045479  66.140625   \n",
       "2018-12-26  63.435986  31.776182  144.184311  37.866348  71.991096  68.271774   \n",
       "2018-12-27  64.345802  31.530161  143.868118  37.620605  72.694504  68.729782   \n",
       "2018-12-28  64.000351  31.323500  144.584229  37.639885  73.672821  69.131706   \n",
       "2018-12-31  65.455811  31.599043  146.444290  38.003681  74.537941  69.542992   \n",
       "\n",
       "                                                          ...     Volume   \n",
       "                  ABT       ACGL         ACN        ADBE  ...       WYNN   \n",
       "Date                                                      ...              \n",
       "1990-01-02   1.846023        NaN         NaN    1.188340  ...        NaN  \\\n",
       "1990-01-03   1.852688        NaN         NaN    1.247023  ...        NaN   \n",
       "1990-01-04   1.849356        NaN         NaN    1.305707  ...        NaN   \n",
       "1990-01-05   1.829362        NaN         NaN    1.335048  ...        NaN   \n",
       "1990-01-08   1.838740        NaN         NaN    1.352692  ...        NaN   \n",
       "...               ...        ...         ...         ...  ...        ...   \n",
       "2018-12-24  60.909615  24.799999  125.596733  205.160004  ...  2225000.0   \n",
       "2018-12-26  64.681633  25.920000  130.614212  222.949997  ...  3506200.0   \n",
       "2018-12-27  65.619972  26.540001  131.929642  225.139999  ...  4229900.0   \n",
       "2018-12-28  66.047363  26.389999  131.375290  223.130005  ...  2316100.0   \n",
       "2018-12-31  67.199402  26.719999  132.493423  226.240005  ...  2609800.0   \n",
       "\n",
       "                                                                         \n",
       "                XEL       XOM     XRAY       XYL        YUM        ZBH   \n",
       "Date                                                                     \n",
       "1990-01-02   247200   5326000    18000       NaN        NaN        NaN  \\\n",
       "1990-01-03   126800   4980400    79200       NaN        NaN        NaN   \n",
       "1990-01-04   204200   6013200    25200       NaN        NaN        NaN   \n",
       "1990-01-05   144800   3854800    92400       NaN        NaN        NaN   \n",
       "1990-01-08   189000   4302000    98400       NaN        NaN        NaN   \n",
       "...             ...       ...      ...       ...        ...        ...   \n",
       "2018-12-24  2810600  14262800  1204200  542800.0  1806000.0   959548.0   \n",
       "2018-12-26  5029800  24887700  2309900  806200.0  2030200.0  1667776.0   \n",
       "2018-12-27  4759500  22077000  2042600  790800.0  2081600.0  1626267.0   \n",
       "2018-12-28  5728300  19710600  1763500  782800.0  1699500.0  1915800.0   \n",
       "2018-12-31  4485400  15807000  1664300  663800.0  1657000.0  1431391.0   \n",
       "\n",
       "                                          \n",
       "                ZBRA     ZION        ZTS  \n",
       "Date                                      \n",
       "1990-01-02       NaN    53600        NaN  \n",
       "1990-01-03       NaN   111200        NaN  \n",
       "1990-01-04       NaN     1600        NaN  \n",
       "1990-01-05       NaN        0        NaN  \n",
       "1990-01-08       NaN     1600        NaN  \n",
       "...              ...      ...        ...  \n",
       "2018-12-24  363000.0  1504800  1551400.0  \n",
       "2018-12-26  327200.0  2969800  1869700.0  \n",
       "2018-12-27  504500.0  2534200  2244700.0  \n",
       "2018-12-28  344800.0  2558600  1797300.0  \n",
       "2018-12-31  409100.0  2575600  1485200.0  \n",
       "\n",
       "[7307 rows x 3018 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EmhPxpT6t8HK"
   },
   "source": [
    "The data does not look at all beautiful and also very difficult to understand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 455
    },
    "id": "xT2_08myuCv1",
    "outputId": "ee30ba0f-730f-4534-b6b4-b31c3ee308ca"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Close</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1999-11-18</th>\n",
       "      <td>A</td>\n",
       "      <td>26.845926</td>\n",
       "      <td>31.473534</td>\n",
       "      <td>35.765381</td>\n",
       "      <td>28.612303</td>\n",
       "      <td>32.546494</td>\n",
       "      <td>62546380.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999-11-19</th>\n",
       "      <td>A</td>\n",
       "      <td>24.634192</td>\n",
       "      <td>28.880545</td>\n",
       "      <td>30.758226</td>\n",
       "      <td>28.478184</td>\n",
       "      <td>30.713518</td>\n",
       "      <td>15234146.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999-11-22</th>\n",
       "      <td>A</td>\n",
       "      <td>26.845926</td>\n",
       "      <td>31.473534</td>\n",
       "      <td>31.473534</td>\n",
       "      <td>28.657009</td>\n",
       "      <td>29.551144</td>\n",
       "      <td>6577870.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999-11-23</th>\n",
       "      <td>A</td>\n",
       "      <td>24.405386</td>\n",
       "      <td>28.612303</td>\n",
       "      <td>31.205294</td>\n",
       "      <td>28.612303</td>\n",
       "      <td>30.400572</td>\n",
       "      <td>5975611.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999-11-24</th>\n",
       "      <td>A</td>\n",
       "      <td>25.053659</td>\n",
       "      <td>29.372318</td>\n",
       "      <td>29.998213</td>\n",
       "      <td>28.612303</td>\n",
       "      <td>28.701717</td>\n",
       "      <td>4843231.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-24</th>\n",
       "      <td>ZTS</td>\n",
       "      <td>77.151314</td>\n",
       "      <td>79.279999</td>\n",
       "      <td>80.910004</td>\n",
       "      <td>78.900002</td>\n",
       "      <td>80.910004</td>\n",
       "      <td>1551400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-26</th>\n",
       "      <td>ZTS</td>\n",
       "      <td>80.693573</td>\n",
       "      <td>82.919998</td>\n",
       "      <td>82.940002</td>\n",
       "      <td>79.139999</td>\n",
       "      <td>79.610001</td>\n",
       "      <td>1869700.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-27</th>\n",
       "      <td>ZTS</td>\n",
       "      <td>82.065720</td>\n",
       "      <td>84.330002</td>\n",
       "      <td>84.330002</td>\n",
       "      <td>81.180000</td>\n",
       "      <td>81.830002</td>\n",
       "      <td>2244700.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-28</th>\n",
       "      <td>ZTS</td>\n",
       "      <td>82.221428</td>\n",
       "      <td>84.489998</td>\n",
       "      <td>85.589996</td>\n",
       "      <td>83.550003</td>\n",
       "      <td>84.830002</td>\n",
       "      <td>1797300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-31</th>\n",
       "      <td>ZTS</td>\n",
       "      <td>83.243240</td>\n",
       "      <td>85.540001</td>\n",
       "      <td>85.589996</td>\n",
       "      <td>84.599998</td>\n",
       "      <td>85.269997</td>\n",
       "      <td>1485200.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2856697 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Symbol  Adj Close      Close       High        Low       Open   \n",
       "Date                                                                       \n",
       "1999-11-18      A  26.845926  31.473534  35.765381  28.612303  32.546494  \\\n",
       "1999-11-19      A  24.634192  28.880545  30.758226  28.478184  30.713518   \n",
       "1999-11-22      A  26.845926  31.473534  31.473534  28.657009  29.551144   \n",
       "1999-11-23      A  24.405386  28.612303  31.205294  28.612303  30.400572   \n",
       "1999-11-24      A  25.053659  29.372318  29.998213  28.612303  28.701717   \n",
       "...           ...        ...        ...        ...        ...        ...   \n",
       "2018-12-24    ZTS  77.151314  79.279999  80.910004  78.900002  80.910004   \n",
       "2018-12-26    ZTS  80.693573  82.919998  82.940002  79.139999  79.610001   \n",
       "2018-12-27    ZTS  82.065720  84.330002  84.330002  81.180000  81.830002   \n",
       "2018-12-28    ZTS  82.221428  84.489998  85.589996  83.550003  84.830002   \n",
       "2018-12-31    ZTS  83.243240  85.540001  85.589996  84.599998  85.269997   \n",
       "\n",
       "                Volume  \n",
       "Date                    \n",
       "1999-11-18  62546380.0  \n",
       "1999-11-19  15234146.0  \n",
       "1999-11-22   6577870.0  \n",
       "1999-11-23   5975611.0  \n",
       "1999-11-24   4843231.0  \n",
       "...                ...  \n",
       "2018-12-24   1551400.0  \n",
       "2018-12-26   1869700.0  \n",
       "2018-12-27   2244700.0  \n",
       "2018-12-28   1797300.0  \n",
       "2018-12-31   1485200.0  \n",
       "\n",
       "[2856697 rows x 7 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = data.stack().reset_index().rename(index=str, columns={\"level_1\": \"Symbol\"}).sort_values(['Symbol','Date'])\n",
    "df.set_index('Date', inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "Vo8G83O07A2f"
   },
   "outputs": [],
   "source": [
    "df.to_csv('../datasets/stock-prices-S&P-constituents/stocks-data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0GbRIIBKfUGT"
   },
   "source": [
    "## Steps to follow - \n",
    "1. We divide our raw data into study periods, where each study period is divided into a training part(for in-sample trading) and a trading part(for out-sample predictions).\n",
    "2. We introduce out features.\n",
    "3. We set up our targets.\n",
    "4. We define our 2 machine learning methods we employ, namely random forest and CuDNNLSTM.\n",
    "5. Establish a trading strategy for trading part."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gsitj69EeR0U"
   },
   "source": [
    "## Data preparation for Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oBHNC--xEvo5"
   },
   "source": [
    "\n",
    "### Preparing the original dataset for further processing\n",
    "\n",
    "*Segregate the stocks within different numpy arrays according to the ticker name.*\n",
    "![Stack-stock-data-on-top-of-each-other.png](https://i.postimg.cc/HnDyJp9s/Stack-stock-data-on-top-of-each-other.png)\n",
    "\n",
    "WARNING❗ \n",
    "- Different stocks will give different no. of rows, as all stocks were not always available in that time span.\n",
    "- Here we are not able to properly get all days values.\n",
    "\n",
    "To prevent the error, we are removing those stocks will are having empty values for those dates.\n",
    "\n",
    "E.g. Stock A might start from 1991-01-01 and Stock B from 1990-12-31 then both of them are not in same shape. So we can remove stock B. Making sure all stocks are having same no of rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "XQ7RCziEVEFv"
   },
   "outputs": [],
   "source": [
    "# Retrieve the data from your drive\n",
    "df = pd.read_csv('../datasets/stock-prices-S&P-constituents/stocks-data.csv')\n",
    "df = df.set_index('Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "vnyAJdbt8bW5"
   },
   "outputs": [],
   "source": [
    "# ticker of each stock\n",
    "symbols = df['Symbol'].unique()\n",
    "\n",
    "n_stocks = len(symbols) # number of stocks\n",
    "n_rows = 7307 # no of stock days from 1990-01-01 to 2018-12-31, calculated 252*29-1=7307\n",
    "\n",
    "stocks = [] # Store the stocks data inside stocks list\n",
    "filtered_symbols = [] # This are the symbols for those stocks which have 7307 rows only\n",
    "\n",
    "# segregate the stocks within different numpy arrays according to the ticker name\n",
    "for i in range(n_stocks):\n",
    "    total_captured_days = np.delete(df[df['Symbol'] == symbols[i]].reset_index().to_numpy(), 1, axis=1).shape[0]\n",
    "    # Just take those stocks which was available from 1990-01-01 to 2018-12-31\n",
    "    if total_captured_days == n_rows:\n",
    "        stocks.append(np.delete(df[df['Symbol'] == symbols[i]].reset_index().to_numpy(), 1, axis=1))\n",
    "        filtered_symbols.append(symbols[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "oRK0iwXSHMNU"
   },
   "outputs": [],
   "source": [
    "# Create a check point\n",
    "final_stocks = stocks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pn8rT3p6A1JQ"
   },
   "source": [
    "*Total number of stocks now are only 251. But we made sure these 251 stocks have same no of rows.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Cc3WKQTmAVGP",
    "outputId": "664fee50-5b02-4ffd-e84c-6ba795d115c3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(251, 251, list)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(final_stocks), len(filtered_symbols), type(final_stocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dm3mgXK1BQNj",
    "outputId": "d7422704-35bb-42ac-9ea2-559edb4f45db"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray, (251, 7307, 7))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the list into array for smooth manipulation of data later\n",
    "final_stocks = np.array(final_stocks)\n",
    "type(final_stocks), final_stocks.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cYxC6JXkBxoz"
   },
   "source": [
    "We just need opening price and adjacent closing price, so we can remove other features like Volume, Min, Max etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "SUih2fNgBbf2",
    "outputId": "c5101b2d-8633-4550-a352-c0aed68346f4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Close</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1990-01-02</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>0.264482</td>\n",
       "      <td>0.332589</td>\n",
       "      <td>0.334821</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.314732</td>\n",
       "      <td>183198400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990-01-03</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>0.266257</td>\n",
       "      <td>0.334821</td>\n",
       "      <td>0.339286</td>\n",
       "      <td>0.334821</td>\n",
       "      <td>0.339286</td>\n",
       "      <td>207995200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990-01-04</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>0.267145</td>\n",
       "      <td>0.335938</td>\n",
       "      <td>0.345982</td>\n",
       "      <td>0.332589</td>\n",
       "      <td>0.341518</td>\n",
       "      <td>221513600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990-01-05</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>0.268033</td>\n",
       "      <td>0.337054</td>\n",
       "      <td>0.341518</td>\n",
       "      <td>0.330357</td>\n",
       "      <td>0.337054</td>\n",
       "      <td>123312000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990-01-08</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>0.269808</td>\n",
       "      <td>0.339286</td>\n",
       "      <td>0.339286</td>\n",
       "      <td>0.330357</td>\n",
       "      <td>0.334821</td>\n",
       "      <td>101572800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-24</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>35.375175</td>\n",
       "      <td>36.707500</td>\n",
       "      <td>37.887501</td>\n",
       "      <td>36.647499</td>\n",
       "      <td>37.037498</td>\n",
       "      <td>148676800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-26</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>37.866348</td>\n",
       "      <td>39.292500</td>\n",
       "      <td>39.307499</td>\n",
       "      <td>36.680000</td>\n",
       "      <td>37.075001</td>\n",
       "      <td>234330000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-27</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>37.620605</td>\n",
       "      <td>39.037498</td>\n",
       "      <td>39.192501</td>\n",
       "      <td>37.517502</td>\n",
       "      <td>38.959999</td>\n",
       "      <td>212468400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-28</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>37.639885</td>\n",
       "      <td>39.057499</td>\n",
       "      <td>39.630001</td>\n",
       "      <td>38.637501</td>\n",
       "      <td>39.375000</td>\n",
       "      <td>169165600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-31</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>38.003681</td>\n",
       "      <td>39.435001</td>\n",
       "      <td>39.840000</td>\n",
       "      <td>39.119999</td>\n",
       "      <td>39.632500</td>\n",
       "      <td>140014000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7307 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Symbol  Adj Close      Close       High        Low       Open   \n",
       "Date                                                                       \n",
       "1990-01-02   AAPL   0.264482   0.332589   0.334821   0.312500   0.314732  \\\n",
       "1990-01-03   AAPL   0.266257   0.334821   0.339286   0.334821   0.339286   \n",
       "1990-01-04   AAPL   0.267145   0.335938   0.345982   0.332589   0.341518   \n",
       "1990-01-05   AAPL   0.268033   0.337054   0.341518   0.330357   0.337054   \n",
       "1990-01-08   AAPL   0.269808   0.339286   0.339286   0.330357   0.334821   \n",
       "...           ...        ...        ...        ...        ...        ...   \n",
       "2018-12-24   AAPL  35.375175  36.707500  37.887501  36.647499  37.037498   \n",
       "2018-12-26   AAPL  37.866348  39.292500  39.307499  36.680000  37.075001   \n",
       "2018-12-27   AAPL  37.620605  39.037498  39.192501  37.517502  38.959999   \n",
       "2018-12-28   AAPL  37.639885  39.057499  39.630001  38.637501  39.375000   \n",
       "2018-12-31   AAPL  38.003681  39.435001  39.840000  39.119999  39.632500   \n",
       "\n",
       "                 Volume  \n",
       "Date                     \n",
       "1990-01-02  183198400.0  \n",
       "1990-01-03  207995200.0  \n",
       "1990-01-04  221513600.0  \n",
       "1990-01-05  123312000.0  \n",
       "1990-01-08  101572800.0  \n",
       "...                 ...  \n",
       "2018-12-24  148676800.0  \n",
       "2018-12-26  234330000.0  \n",
       "2018-12-27  212468400.0  \n",
       "2018-12-28  169165600.0  \n",
       "2018-12-31  140014000.0  \n",
       "\n",
       "[7307 rows x 7 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['Symbol']=='AAPL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r-2dOHPUCTok",
    "outputId": "514599eb-ebab-4d4f-e202-7a4cad67f773"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['1990-01-02', 0.264482170343399, 0.3325890004634857,\n",
       "       0.3348209857940674, 0.3125, 0.3147319853305816, 183198400.0],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_stocks[0, 0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IZ8wIkCVDDd8",
    "outputId": "7440b2c1-7a5a-4fd3-d62c-bcaed33a58c4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.3325890004634857, 0.3348209857940674], dtype=object), 183198400.0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_stocks[0, 0, 2:4], final_stocks[0, 0, 6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SEFs5XIrDqWB",
    "outputId": "f7115a92-8893-49ab-d860-ac04fbcf2eeb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(251, 7307, 3)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_stocks = np.delete(final_stocks, np.s_[2:5], axis=2) # Delete Close, High, Low columns \n",
    "final_stocks = np.delete(final_stocks, 3, axis=2) # Delete Volume column, NOTE after first deletion index is changed\n",
    "final_stocks.shape # Now it only contains Date, Adj Close and Open"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "TlimZxg8Bb5k"
   },
   "outputs": [],
   "source": [
    "final_stocks[:, :, 0] = np.array([pd.to_datetime(stock_i).date for stock_i in final_stocks[:, :, 0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vkjzcCvvRRgT",
    "outputId": "24ca546c-f8ab-426b-8d46-c163c777c1d4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.date(1990, 1, 2)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_stocks[0, 0, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9luoTa3nnVa8"
   },
   "source": [
    "### Datasets creation with non-overlapping testing period from original dataset\n",
    "\n",
    "We divide the dataset contsisting of 29 years starting from January 1990 till December 2018, using a 4-year window, 1-year stride, where each study period is divided into a training part(of 756 days almost = 3 years) and trading part(of 252 days almost = 1 year).\n",
    "\n",
    "So, we obtain 26 study periods with non-overlapping trading part.\n",
    "\n",
    "![Dataset-creation-with-non-overlapping-testing-period.png](https://i.postimg.cc/7YWw5YwL/Dataset-creation-with-non-overlapping-testing-period.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BNa54mX2juGf"
   },
   "source": [
    "**METHOD TO CREATE THE NON-OVERLAPPING TESTING PERIODS**\n",
    "\n",
    "1. Store the dates inside temp variable.\n",
    "\n",
    "  ![dates-layed-out-in-stock-price-prediction.png](https://i.postimg.cc/65MCHfGk/dates-layed-out-in-stock-price-prediction.png)\n",
    "\n",
    "2. Define 2 variables. `year_start` that will point to the starting day of each dataset and `start_index` which will tell what is the exact index number of that starting day.\n",
    "  ![year-start-start-index-variables.png](https://i.postimg.cc/MGvP8krx/year-start-start-index-variables.png)\n",
    "\n",
    "3. `year_start` will go till `2015`. As 2015-2018 is the last last study period.\n",
    "\n",
    "4. Another variable called `year_end` will point to the end of the year. To be precise it is not exactly the end of the last year but one day after the last day. I.e. if the `year_start = '1990-01-02'` then `year_end = '1994-01-02'`.\n",
    "\n",
    "  Why this will make any sense?\n",
    "\n",
    "  The reason is, we will try to find the exact index value of the first day and last day inside each dataset.\n",
    "  Then, we will use condition indexing using those indexes. Now, we made the `year_end` like that because it will take less efforts to change the year value of `year_start` by `window_size` to get `year_end`. Then, in the condition we not include this `year_end`.\n",
    "  \n",
    "  ![year-end.png](https://i.postimg.cc/XY9CjPWR/year-end.png)\n",
    "\n",
    "5. Index the `temp` that contained the whole 29 years time from `year_start`(including) to `year_end`(excluding). Condition will be `temp[(temp>=year_start) & (temp<year_end)]`. This is the `timeline` of the current dataset(not yet created!).\n",
    "  ![timeline-creation.png](https://i.postimg.cc/JzrDkWfL/timeline-creation.png)\n",
    "\n",
    "6. Calculate the `end_index` using the length of the current dataset's timeline and `start_index`. \n",
    "  \n",
    "  `end_index = start_index + len(timeline)`\n",
    "  ![progress-of-end-index.png](https://i.postimg.cc/T2rzsZHB/progress-of-end-index.png)\n",
    "\n",
    "7. Slice the data from `start_index` to `end_index`(excluding). As the date is now useless for our further steps. So make sure to delete the date part by slicing from `index=1` till end as date's index = 0.\n",
    "\n",
    "  `data[:, start_index:end_index, 1:]`\n",
    "  \n",
    "  Then append it to `datasets` list.\n",
    "\n",
    "8. Finally update the `year_start` by moving the previous `year_start` `stride=1` year. If the `year_start` is `1990-01-02` then next time it will be `1991-01-02`.\n",
    "![progress-year-start.png](https://i.postimg.cc/HkwvsY30/progress-year-start.png)\n",
    "\n",
    "9. Now, as we have the new `year_start`, we will use it to find the `before_start_timeline` that has passed from `1990-01-02`. This timeline will store the days from `1990-01-02` to the current `year_start` date.\n",
    "\n",
    "  It will help us find the new `start_index`. We need to just find the length of this `before_start_timeline` or in other words how many days have passed from `1990-01-02` till the current `year_start`.\n",
    "\n",
    "![progress-of-start-index.png](https://i.postimg.cc/dtcKLdWy/progress-of-start-index.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "gDCpLlpAosKr"
   },
   "outputs": [],
   "source": [
    "def dataset_generator(data, window_size=4, stride=1):\n",
    "    '''\n",
    "    data: stocks data containing date from 1990 to 2018 -> dims = (_, _, _)\n",
    "    window_size: no of years contained inside any dataset -> int\n",
    "    stride: by how much amount the window should slide -> int\n",
    "\n",
    "    returns list of datasets each having 'window_size'ed years of stock data -> list\n",
    "    '''\n",
    "\n",
    "    # datasets -> [D1, D2, D3, ..., D26], Di will be a (251, 4 year time length, 2)\n",
    "    datasets = []\n",
    "\n",
    "    # Step 1\n",
    "    temp = data[0, :, 0]\n",
    "\n",
    "    # Step 2\n",
    "    year_start = data[0, 0, 0]\n",
    "    start_index = 0\n",
    "\n",
    "    # Step 3\n",
    "    while year_start.year<=2015:\n",
    "\n",
    "        # Step 4\n",
    "        year_end = year_start.replace(year=year_start.year+window_size)\n",
    "\n",
    "        # Step 5\n",
    "        timeline = temp[(temp>=year_start) & (temp<year_end)]\n",
    "\n",
    "        # Step 6\n",
    "        end_index = start_index + timeline.shape[0]\n",
    "\n",
    "        # Step 7\n",
    "        datasets.append(data[:, start_index:end_index, 1:])\n",
    "\n",
    "        # Step 8\n",
    "        year_start = year_start.replace(year=year_start.year+stride)\n",
    "\n",
    "        # Step 9\n",
    "        before_start_timeline = temp[temp<=year_start]\n",
    "        start_index = len(before_start_timeline)\n",
    "\n",
    "    return datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "h8j2AUn1lXsl"
   },
   "outputs": [],
   "source": [
    "datasets = dataset_generator(final_stocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tFGvZ2Qjl1ot",
    "outputId": "d74fccc6-34e4-4600-a420-6e3854cb4e8a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UBpVmyNBRoAw",
    "outputId": "66b541a2-08ab-4f58-d593-7f3db062b808"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(251, 1013, 2)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r9msDvwqRr2j",
    "outputId": "84593a9f-40e2-4379-c2a8-176feec2dbd3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.264482170343399, 0.3147319853305816], dtype=object)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets[0][0, 0, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nGfwf7F4Wkoo"
   },
   "source": [
    "Order of values for the above result : *Adj Close, Open*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "HqCYVnuZXK2B"
   },
   "outputs": [],
   "source": [
    "main_datasets = datasets # Create checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AcJwB422SGMb"
   },
   "source": [
    "## Features Selection\n",
    "\n",
    "Let $T_{study}$ denote the total amount of days in a study period and $n_i$ represent the number of stocks $s$ in $S$ having complete historical data available at the end of each study period $i$. Moreover, we define the adjacent closing price and opening price of any stock $s \\in S$ at time $t$ by $cp^{(s)}_t$ and $op^{(s)}_t$.\n",
    "\n",
    "Given a prediction day $t:=\\tau$, we have the following inputs and prediction task.\n",
    "\n",
    "Input: We have the historical opening prices, $op^{(s)}_t, t \\in \\{ 0, 1, ..., \\tau -1, \\tau\\}$, (including the opening price of the prediction day $op^{(s)}_\\tau$) as well as the historical adjacent closing prices, $cp^{(s)}_t, t \\in \\{ 0, 1, ..., \\tau -1\\}$, (excluding the opening price of the prediction day $cp^{(s)}_\\tau$).\n",
    "\n",
    "Task: Out of all n stocks, predict k stocks with highest and k stocks with lowest intraday return $ir_{\\tau, 0} = \\dfrac{cp_\\tau}{op_\\tau} - 1$.\n",
    "\n",
    "**NOTE:** In the original paper they used all the stocks that could be scrapped from the web. Then they divided each stock into 26 datasets. Now, in this 26 datasets, some datasets may contain all 492 stocks that were originally scrapped and some datasets may contain only 251 stocks. That is why it is saying $s \\in S$ because each dataset will have different number of stocks and that will be a subset of all the originally scrapped stocks.\n",
    "\n",
    "But, in our case we are dealing with only those stocks which has all entries filled from 1990-01-02 to 2018-12-31. So, we have 251 stocks in all the datasets.\n",
    "\n",
    "\n",
    "\n",
    "For LaTex markdown, refer to this page: [here](https://ashki23.github.io/markdown-latex.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dus29JN9SJUZ"
   },
   "source": [
    "### Feature generation for Random Forest\n",
    "\n",
    "For any stock $s \\in S$ and any time $t \\in \\{ 241, 242, ..., T_{study} \\}$, the feature set we provide to the random forest comprises of 3 signal:\n",
    "\n",
    "1. Intraday return: $ir^{(s)}_{t, m} := \\dfrac{cp^{(s)}_{t-m}}{op^{(s)}_{t-m}} - 1$,\n",
    "\n",
    "\n",
    "2. Returns with respect to last closing price: $cr^{(s)}_{t, m} := \\dfrac{cp^{(s)}_{t-1}}{cp^{(s)}_{t-1-m}} - 1$,\n",
    "\n",
    "\n",
    "3. Returns with respect to opening price: $or^{(s)}_{t, m} := \\dfrac{op^{(s)}_{t}}{cp^{(s)}_{t-m}} - 1$,\n",
    "\n",
    "where $m \\in \\{ 1, 2, 3, ..., 20 \\} \\cup \\{ 40, 60, 80, ...., 240 \\}$, obtaining 93 features. By the choice of m we consider in the first month the corresponding returns of each trading day, whereas for the subsequent 11 months we only consider the corresponding multi-period returns of each month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ldq-ByUHPO-i",
    "outputId": "c8e6714e-229c-4292-c90e-065a3b45e2b8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(main_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "3EuH1cKcGM0j"
   },
   "outputs": [],
   "source": [
    "# This function will generate new features for Random Forest\n",
    "def generate_features_rf(curr_dataset):\n",
    "\n",
    "    # Take the total amount of days in 1st study period\n",
    "    T_study = curr_dataset.shape[1]\n",
    "    print(\"current dataset has\", T_study, \" days.\")\n",
    "\n",
    "    # Create the t =[241, 243, ..., T_study]\n",
    "    t = np.arange(240, T_study)\n",
    "\n",
    "    # Define the m for calculation of t-m, m = [1, 2, 3, ..., 20]\n",
    "    M = np.arange(1, 21)\n",
    "\n",
    "    # m = [1, 2, 3, ..., 20] U [40, 60, 80, ..., 240]\n",
    "    M = np.concatenate((M, np.arange(40, 241, 20)))\n",
    "\n",
    "    # Define number of stocks as it will be used to create arrays with proper shapes\n",
    "    n_stocks = 251\n",
    "\n",
    "    # Create a container to store ir, cr and or for the current dataset\n",
    "    container = np.ones(shape=(n_stocks, T_study, M.shape[0]*3))\n",
    "\n",
    "    # Put NaN values to the first 240 rows as it will be used for feature creation\n",
    "    container[:, :t[0], :] = np.nan \n",
    "\n",
    "\n",
    "    # To calculate ir, we need cp_(t-m) and op_(t-m)\n",
    "    cp_t_m = np.zeros((n_stocks, t.shape[0], M.shape[0]))\n",
    "    op_t_m = np.zeros((n_stocks, t.shape[0], M.shape[0]))\n",
    "\n",
    "    # To calculate cr, we need cp_(t-1-m) and cp_(t-1-m). Remember we are indexing from 0, not 1!\n",
    "    cp_t_1_m = np.zeros((n_stocks, t.shape[0], M.shape[0]))\n",
    "    cp_t_1 = curr_dataset[:, t-2, 0]\n",
    "\n",
    "    # To calculate or, we need op_t and cp_t_m. Remember we are indexing from 0, not 1!\n",
    "    op_t = curr_dataset[:, t-1, 1]\n",
    "\n",
    "\n",
    "    # Calculate cp_(t-m), op_(t-m) and cp_(t-1-m) for each m and store them at proper axis=2 index i\n",
    "    # of their respective container\n",
    "    for i, m in enumerate(M):\n",
    "        cp_t_m[:, :, i] = curr_dataset[:, t-m, 0]\n",
    "        op_t_m[:, :, i] = curr_dataset[:, t-m, 1]\n",
    "        cp_t_1_m[:, :, i] = curr_dataset[:, t-1-m, 0]\n",
    "\n",
    "\n",
    "    # Calculate ir_(t-m)\n",
    "    ir_t_m = np.divide(cp_t_m, op_t_m, out=np.zeros_like(cp_t_m), where=op_t_m!=0) - 1\n",
    "\n",
    "\n",
    "    # Before calculating cr_(t-m), reshape the cp_(t-1-m) as it should have the same last part of shape as cp_(t-1), the divident\n",
    "    # means if cp_(t-1) is (251, 774) then cp_(t-1-m) should be (_, 251, 774) notice the last of shape is same\n",
    "    reshaped_cp_t_1_m = cp_t_1_m.reshape(M.shape[0], n_stocks, -1)\n",
    "\n",
    "    # Calculating cr_(t-m)\n",
    "    cr_t_m = np.divide(cp_t_1, reshaped_cp_t_1_m, where=reshaped_cp_t_1_m!=0).reshape(n_stocks, -1, M.shape[0]) - 1\n",
    "\n",
    "\n",
    "    # Before calculating or_(t-m), reshape the cp_(t-m) as it should have the same last part of shape as op_t, the divident\n",
    "    # means if op_t is (251, 774) then cp_(t-m) should be (_, 251, 774) notice the last of shape is same\n",
    "    reshaped_cp_t_m = cp_t_m.reshape(M.shape[0], n_stocks, -1)\n",
    "\n",
    "    # Calculating or_(t-m)\n",
    "    or_t_m = np.divide(op_t, reshaped_cp_t_m, where=reshaped_cp_t_m!=0).reshape(n_stocks, -1, M.shape[0]) - 1\n",
    "\n",
    "\n",
    "    # Put the ir, cr and or inside the container\n",
    "    container[:, t, :] = np.dstack((ir_t_m, cr_t_m, or_t_m))\n",
    "\n",
    "    return container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LGRA1qIdxSDH",
    "outputId": "5273cfe5-6dc8-454e-f7f6-5e2b4178849a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current dataset has 1013  days.\n",
      "current dataset has 1012  days.\n",
      "current dataset has 1011  days.\n",
      "current dataset has 1011  days.\n",
      "current dataset has 1011  days.\n",
      "current dataset has 1011  days.\n",
      "current dataset has 1011  days.\n",
      "current dataset has 1009  days.\n",
      "current dataset has 1004  days.\n",
      "current dataset has 1004  days.\n",
      "current dataset has 1004  days.\n",
      "current dataset has 1004  days.\n",
      "current dataset has 1008  days.\n",
      "current dataset has 1007  days.\n",
      "current dataset has 1006  days.\n",
      "current dataset has 1007  days.\n",
      "current dataset has 1007  days.\n",
      "current dataset has 1008  days.\n",
      "current dataset has 1009  days.\n",
      "current dataset has 1006  days.\n",
      "current dataset has 1006  days.\n",
      "current dataset has 1006  days.\n",
      "current dataset has 1006  days.\n",
      "current dataset has 1008  days.\n",
      "current dataset has 1007  days.\n",
      "current dataset has 1005  days.\n"
     ]
    }
   ],
   "source": [
    "# It will contain all the newly processed datasets each with a shape (251, stock days in 4 years, 93)\n",
    "containers = []\n",
    "\n",
    "# Run the generate_feature_rf function for each dataset inside main_datasets\n",
    "for dataset in main_datasets:\n",
    "    containers.append(generate_features_rf(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bmfSm43DyHD1",
    "outputId": "53dd852b-b649-41d0-f3aa-9547a88315ea"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(containers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PvuESLpv1-nq"
   },
   "source": [
    "### Feature generation for LSTM\n",
    "\n",
    "We input the model with 240 timesteps and 3 features and train it to predict the direction of the $241^{st}$ intraday return.\n",
    "\n",
    "More precisely, for each stock $s$ at time $t$, we first consider the following three features $ir^{(s)}_{t, 1}, cr^{(s)}_{t, 1}, or^{(s)}_{t, 1}$ defined above.\n",
    "\n",
    "Then we apply the Robust Scaler Standardization\n",
    "\n",
    "$\\tilde f^{(s)}_{t, 1} := \\dfrac {f^{(s)}_{t,1} - Q_2(f^{(s)}_{.,1})} {Q_3(f^{(s)}_{.,1}) - Q_1(f^{(s)}_{.,1})}$\n",
    "\n",
    "where $Q_1(f^{(s)}_{.,1}), Q_2(f^{(s)}_{.,1})$ and $Q_3(f^{(s)}_{.,1})$ are the first, second and third quartile of $f^{(s)}_{.,1}$, for each feature $f^{(s)}_{.,1} \\in \\{ ir^{(s)}_{., 1}, cr^{(s)}_{., 1}, or^{(s)}_{., 1} \\}$ in the respective training period.\n",
    "\n",
    "The Robust Scaler Standardization first subtracts (and hence removes) the median and then scales the data using the inter-quartile range, making it robust to outliers.\n",
    "\n",
    "Next for each time $t \\in \\{ 240, 241, ..., T_study \\}$, we generate overlapping sequence of 240 consecutive, three-dimensional standardized features $\\{ \\tilde F^{(s)}_{t-239,1}, \\tilde F^{(s)}_{t-238,1}, ..., \\tilde F^{(s)}_{t,1} \\}$, where $\\tilde F^{(s)}_{t-i,1} := (\\tilde ir^{(s)}_{t-i,1}, \\tilde cr^{(s)}_{t-i,1}, \\tilde or^{(s)}_{t-i,1}), i \\in \\{ 239, 238, ..., 0 \\}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rg1yPnfL2EAP"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "7JsDmuufYS1K",
    "Gzrx5Q7DYixY",
    "oBHNC--xEvo5",
    "9luoTa3nnVa8",
    "dus29JN9SJUZ"
   ],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "stock-kernel",
   "language": "python",
   "name": "stock-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
